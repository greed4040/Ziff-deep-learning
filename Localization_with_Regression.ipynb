{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Localization_with_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greed4040/Ziff-deep-learning/blob/master/Localization_with_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5YBsdeoakjv",
        "colab_type": "text"
      },
      "source": [
        "# Object Detection with Bounding Box Regression\n",
        "\n",
        "This notebook will demonstrate some of the basic steps in object detection. Bounding box regression, as the name suggests, makes a regressor model which directly outputs the bounding box coordinates given an image.\n",
        "\n",
        "This concept has been internal to object detectors like [YOLO](https://arxiv.org/abs/1506.02640).\n",
        "\n",
        "Note: If you are running this notebook on Colab itself, I insist you turn on the GPU runtime. Go to **Tools ~> Runtime ~> Change runtime type ~> Hardware Accelerator ~> Select \"GPU\"**\n",
        "\n",
        "Let's Start!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWtbHg3UddHf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 1) Importing the packages\n",
        "\n",
        "We import TensorFlow and Keras along with our beloved NumPy. We print the TensorFlow version we're using.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTg_2ZBqFM2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e718ccbc-2bc6-405c-d081-fa08a5bccbc8"
      },
      "source": [
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyVzlExRduu-",
        "colab_type": "text"
      },
      "source": [
        "## 2) Downloading the data from GitHub\n",
        "\n",
        "We need to download our dataset from the [Dataset_Archives](https://github.com/shubham0204/Dataset_Archives) repo where I have hosted a ZIP file of the dataset. The original dataset hails from [Kaggle.com](https://www.kaggle.com) as [Image Localization Dataset](https://www.kaggle.com/mbkinaci/image-localization-dataset) by [Muhammed Buyukkinaci](https://www.kaggle.com/mbkinaci).\n",
        "\n",
        "Also, we install the [xmltodict](https://pypi.org/project/xmltodict/) package from PyPI which will be useful to parse the XML files containing the bounding box annotations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dIf16k6FT68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e26138ff-a18a-465d-8ffe-6db3594dec81"
      },
      "source": [
        "\n",
        "!pip install xmltodict\n",
        "!wget https://github.com/shubham0204/Dataset_Archives/blob/master/image-localization-dataset.zip?raw=true -O data.zip\n",
        "!unzip data.zip\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n",
            "--2020-03-10 10:33:47--  https://github.com/shubham0204/Dataset_Archives/blob/master/image-localization-dataset.zip?raw=true\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/shubham0204/Dataset_Archives/raw/master/image-localization-dataset.zip [following]\n",
            "--2020-03-10 10:33:47--  https://github.com/shubham0204/Dataset_Archives/raw/master/image-localization-dataset.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/shubham0204/Dataset_Archives/master/image-localization-dataset.zip [following]\n",
            "--2020-03-10 10:33:48--  https://raw.githubusercontent.com/shubham0204/Dataset_Archives/master/image-localization-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2823971 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.69M  11.0MB/s    in 0.2s    \n",
            "\n",
            "2020-03-10 10:33:49 (11.0 MB/s) - ‘data.zip’ saved [2823971/2823971]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: training_images/\n",
            "  inflating: training_images/cucumber_1.jpg  \n",
            "  inflating: training_images/cucumber_1.xml  \n",
            "  inflating: training_images/cucumber_10.jpg  \n",
            "  inflating: training_images/cucumber_10.xml  \n",
            "  inflating: training_images/cucumber_11.jpg  \n",
            "  inflating: training_images/cucumber_11.xml  \n",
            "  inflating: training_images/cucumber_12.jpg  \n",
            "  inflating: training_images/cucumber_12.xml  \n",
            "  inflating: training_images/cucumber_13.jpg  \n",
            "  inflating: training_images/cucumber_13.xml  \n",
            "  inflating: training_images/cucumber_14.jpg  \n",
            "  inflating: training_images/cucumber_14.xml  \n",
            "  inflating: training_images/cucumber_15.jpg  \n",
            "  inflating: training_images/cucumber_15.xml  \n",
            "  inflating: training_images/cucumber_16.jpg  \n",
            "  inflating: training_images/cucumber_16.xml  \n",
            "  inflating: training_images/cucumber_17.jpg  \n",
            "  inflating: training_images/cucumber_17.xml  \n",
            "  inflating: training_images/cucumber_18.jpg  \n",
            "  inflating: training_images/cucumber_18.xml  \n",
            "  inflating: training_images/cucumber_19.jpg  \n",
            "  inflating: training_images/cucumber_19.xml  \n",
            "  inflating: training_images/cucumber_2.jpg  \n",
            "  inflating: training_images/cucumber_2.xml  \n",
            "  inflating: training_images/cucumber_20.jpg  \n",
            "  inflating: training_images/cucumber_20.xml  \n",
            "  inflating: training_images/cucumber_21.jpg  \n",
            "  inflating: training_images/cucumber_21.xml  \n",
            "  inflating: training_images/cucumber_22.jpg  \n",
            "  inflating: training_images/cucumber_22.xml  \n",
            "  inflating: training_images/cucumber_23.jpg  \n",
            "  inflating: training_images/cucumber_23.xml  \n",
            "  inflating: training_images/cucumber_24.jpg  \n",
            "  inflating: training_images/cucumber_24.xml  \n",
            "  inflating: training_images/cucumber_25.jpg  \n",
            "  inflating: training_images/cucumber_25.xml  \n",
            "  inflating: training_images/cucumber_26.jpg  \n",
            "  inflating: training_images/cucumber_26.xml  \n",
            "  inflating: training_images/cucumber_27.jpg  \n",
            "  inflating: training_images/cucumber_27.xml  \n",
            "  inflating: training_images/cucumber_28.jpg  \n",
            "  inflating: training_images/cucumber_28.xml  \n",
            "  inflating: training_images/cucumber_29.jpg  \n",
            "  inflating: training_images/cucumber_29.xml  \n",
            "  inflating: training_images/cucumber_3.jpg  \n",
            "  inflating: training_images/cucumber_3.xml  \n",
            "  inflating: training_images/cucumber_30.jpg  \n",
            "  inflating: training_images/cucumber_30.xml  \n",
            "  inflating: training_images/cucumber_31.jpg  \n",
            "  inflating: training_images/cucumber_31.xml  \n",
            "  inflating: training_images/cucumber_32.jpg  \n",
            "  inflating: training_images/cucumber_32.xml  \n",
            "  inflating: training_images/cucumber_33.jpg  \n",
            "  inflating: training_images/cucumber_33.xml  \n",
            "  inflating: training_images/cucumber_34.jpg  \n",
            "  inflating: training_images/cucumber_34.xml  \n",
            "  inflating: training_images/cucumber_35.jpg  \n",
            "  inflating: training_images/cucumber_35.xml  \n",
            "  inflating: training_images/cucumber_36.jpg  \n",
            "  inflating: training_images/cucumber_36.xml  \n",
            "  inflating: training_images/cucumber_37.jpg  \n",
            "  inflating: training_images/cucumber_37.xml  \n",
            "  inflating: training_images/cucumber_38.jpg  \n",
            "  inflating: training_images/cucumber_38.xml  \n",
            "  inflating: training_images/cucumber_39.jpg  \n",
            "  inflating: training_images/cucumber_39.xml  \n",
            "  inflating: training_images/cucumber_4.jpg  \n",
            "  inflating: training_images/cucumber_4.xml  \n",
            "  inflating: training_images/cucumber_40.jpg  \n",
            "  inflating: training_images/cucumber_40.xml  \n",
            "  inflating: training_images/cucumber_41.jpg  \n",
            "  inflating: training_images/cucumber_41.xml  \n",
            "  inflating: training_images/cucumber_42.jpg  \n",
            "  inflating: training_images/cucumber_42.xml  \n",
            "  inflating: training_images/cucumber_43.jpg  \n",
            "  inflating: training_images/cucumber_43.xml  \n",
            "  inflating: training_images/cucumber_44.jpg  \n",
            "  inflating: training_images/cucumber_44.xml  \n",
            "  inflating: training_images/cucumber_45.jpg  \n",
            "  inflating: training_images/cucumber_45.xml  \n",
            "  inflating: training_images/cucumber_46.jpg  \n",
            "  inflating: training_images/cucumber_46.xml  \n",
            "  inflating: training_images/cucumber_47.jpg  \n",
            "  inflating: training_images/cucumber_47.xml  \n",
            "  inflating: training_images/cucumber_48.jpg  \n",
            "  inflating: training_images/cucumber_48.xml  \n",
            "  inflating: training_images/cucumber_49.jpg  \n",
            "  inflating: training_images/cucumber_49.xml  \n",
            "  inflating: training_images/cucumber_5.jpg  \n",
            "  inflating: training_images/cucumber_5.xml  \n",
            "  inflating: training_images/cucumber_50.jpg  \n",
            "  inflating: training_images/cucumber_50.xml  \n",
            "  inflating: training_images/cucumber_51.jpg  \n",
            "  inflating: training_images/cucumber_51.xml  \n",
            "  inflating: training_images/cucumber_52.jpg  \n",
            "  inflating: training_images/cucumber_52.xml  \n",
            "  inflating: training_images/cucumber_53.jpg  \n",
            "  inflating: training_images/cucumber_53.xml  \n",
            "  inflating: training_images/cucumber_54.jpg  \n",
            "  inflating: training_images/cucumber_54.xml  \n",
            "  inflating: training_images/cucumber_55.jpg  \n",
            "  inflating: training_images/cucumber_55.xml  \n",
            "  inflating: training_images/cucumber_56.jpg  \n",
            "  inflating: training_images/cucumber_56.xml  \n",
            "  inflating: training_images/cucumber_57.jpg  \n",
            "  inflating: training_images/cucumber_57.xml  \n",
            "  inflating: training_images/cucumber_58.jpg  \n",
            "  inflating: training_images/cucumber_58.xml  \n",
            "  inflating: training_images/cucumber_59.jpg  \n",
            "  inflating: training_images/cucumber_59.xml  \n",
            "  inflating: training_images/cucumber_6.jpg  \n",
            "  inflating: training_images/cucumber_6.xml  \n",
            "  inflating: training_images/cucumber_60.jpg  \n",
            "  inflating: training_images/cucumber_60.xml  \n",
            "  inflating: training_images/cucumber_61.jpg  \n",
            "  inflating: training_images/cucumber_61.xml  \n",
            "  inflating: training_images/cucumber_62.jpg  \n",
            "  inflating: training_images/cucumber_62.xml  \n",
            "  inflating: training_images/cucumber_63.jpg  \n",
            "  inflating: training_images/cucumber_63.xml  \n",
            "  inflating: training_images/cucumber_7.jpg  \n",
            "  inflating: training_images/cucumber_7.xml  \n",
            "  inflating: training_images/cucumber_8.jpg  \n",
            "  inflating: training_images/cucumber_8.xml  \n",
            "  inflating: training_images/cucumber_9.jpg  \n",
            "  inflating: training_images/cucumber_9.xml  \n",
            "  inflating: training_images/eggplant_1.jpg  \n",
            "  inflating: training_images/eggplant_1.xml  \n",
            "  inflating: training_images/eggplant_10.jpg  \n",
            "  inflating: training_images/eggplant_10.xml  \n",
            "  inflating: training_images/eggplant_11.jpg  \n",
            "  inflating: training_images/eggplant_11.xml  \n",
            "  inflating: training_images/eggplant_12.jpg  \n",
            "  inflating: training_images/eggplant_12.xml  \n",
            "  inflating: training_images/eggplant_13.jpg  \n",
            "  inflating: training_images/eggplant_13.xml  \n",
            "  inflating: training_images/eggplant_14.jpg  \n",
            "  inflating: training_images/eggplant_14.xml  \n",
            "  inflating: training_images/eggplant_15.jpg  \n",
            "  inflating: training_images/eggplant_15.xml  \n",
            "  inflating: training_images/eggplant_16.jpg  \n",
            "  inflating: training_images/eggplant_16.xml  \n",
            "  inflating: training_images/eggplant_17.jpg  \n",
            "  inflating: training_images/eggplant_17.xml  \n",
            "  inflating: training_images/eggplant_18.jpg  \n",
            "  inflating: training_images/eggplant_18.xml  \n",
            "  inflating: training_images/eggplant_19.jpg  \n",
            "  inflating: training_images/eggplant_19.xml  \n",
            "  inflating: training_images/eggplant_2.jpg  \n",
            "  inflating: training_images/eggplant_2.xml  \n",
            "  inflating: training_images/eggplant_20.jpg  \n",
            "  inflating: training_images/eggplant_20.xml  \n",
            "  inflating: training_images/eggplant_21.jpg  \n",
            "  inflating: training_images/eggplant_21.xml  \n",
            "  inflating: training_images/eggplant_22.jpg  \n",
            "  inflating: training_images/eggplant_22.xml  \n",
            "  inflating: training_images/eggplant_23.jpg  \n",
            "  inflating: training_images/eggplant_23.xml  \n",
            "  inflating: training_images/eggplant_24.jpg  \n",
            "  inflating: training_images/eggplant_24.xml  \n",
            "  inflating: training_images/eggplant_25.jpg  \n",
            "  inflating: training_images/eggplant_25.xml  \n",
            "  inflating: training_images/eggplant_26.jpg  \n",
            "  inflating: training_images/eggplant_26.xml  \n",
            "  inflating: training_images/eggplant_27.jpg  \n",
            "  inflating: training_images/eggplant_27.xml  \n",
            "  inflating: training_images/eggplant_28.jpg  \n",
            "  inflating: training_images/eggplant_28.xml  \n",
            "  inflating: training_images/eggplant_29.jpg  \n",
            "  inflating: training_images/eggplant_29.xml  \n",
            "  inflating: training_images/eggplant_3.jpg  \n",
            "  inflating: training_images/eggplant_3.xml  \n",
            "  inflating: training_images/eggplant_30.jpg  \n",
            "  inflating: training_images/eggplant_30.xml  \n",
            "  inflating: training_images/eggplant_31.jpg  \n",
            "  inflating: training_images/eggplant_31.xml  \n",
            "  inflating: training_images/eggplant_32.jpg  \n",
            "  inflating: training_images/eggplant_32.xml  \n",
            "  inflating: training_images/eggplant_33.jpg  \n",
            "  inflating: training_images/eggplant_33.xml  \n",
            "  inflating: training_images/eggplant_34.jpg  \n",
            "  inflating: training_images/eggplant_34.xml  \n",
            "  inflating: training_images/eggplant_35.jpg  \n",
            "  inflating: training_images/eggplant_35.xml  \n",
            "  inflating: training_images/eggplant_36.jpg  \n",
            "  inflating: training_images/eggplant_36.xml  \n",
            "  inflating: training_images/eggplant_37.jpg  \n",
            "  inflating: training_images/eggplant_37.xml  \n",
            "  inflating: training_images/eggplant_38.jpg  \n",
            "  inflating: training_images/eggplant_38.xml  \n",
            "  inflating: training_images/eggplant_39.jpg  \n",
            "  inflating: training_images/eggplant_39.xml  \n",
            "  inflating: training_images/eggplant_4.jpg  \n",
            "  inflating: training_images/eggplant_4.xml  \n",
            "  inflating: training_images/eggplant_40.jpg  \n",
            "  inflating: training_images/eggplant_40.xml  \n",
            "  inflating: training_images/eggplant_41.jpg  \n",
            "  inflating: training_images/eggplant_41.xml  \n",
            "  inflating: training_images/eggplant_42.jpg  \n",
            "  inflating: training_images/eggplant_42.xml  \n",
            "  inflating: training_images/eggplant_43.jpg  \n",
            "  inflating: training_images/eggplant_43.xml  \n",
            "  inflating: training_images/eggplant_44.jpg  \n",
            "  inflating: training_images/eggplant_44.xml  \n",
            "  inflating: training_images/eggplant_45.jpg  \n",
            "  inflating: training_images/eggplant_45.xml  \n",
            "  inflating: training_images/eggplant_46.jpg  \n",
            "  inflating: training_images/eggplant_46.xml  \n",
            "  inflating: training_images/eggplant_47.jpg  \n",
            "  inflating: training_images/eggplant_47.xml  \n",
            "  inflating: training_images/eggplant_48.jpg  \n",
            "  inflating: training_images/eggplant_48.xml  \n",
            "  inflating: training_images/eggplant_49.jpg  \n",
            "  inflating: training_images/eggplant_49.xml  \n",
            "  inflating: training_images/eggplant_5.jpg  \n",
            "  inflating: training_images/eggplant_5.xml  \n",
            "  inflating: training_images/eggplant_50.jpg  \n",
            "  inflating: training_images/eggplant_50.xml  \n",
            "  inflating: training_images/eggplant_51.jpg  \n",
            "  inflating: training_images/eggplant_51.xml  \n",
            "  inflating: training_images/eggplant_52.jpg  \n",
            "  inflating: training_images/eggplant_52.xml  \n",
            "  inflating: training_images/eggplant_53.jpg  \n",
            "  inflating: training_images/eggplant_53.xml  \n",
            "  inflating: training_images/eggplant_54.jpg  \n",
            "  inflating: training_images/eggplant_54.xml  \n",
            "  inflating: training_images/eggplant_55.jpg  \n",
            "  inflating: training_images/eggplant_55.xml  \n",
            "  inflating: training_images/eggplant_56.jpg  \n",
            "  inflating: training_images/eggplant_56.xml  \n",
            "  inflating: training_images/eggplant_57.jpg  \n",
            "  inflating: training_images/eggplant_57.xml  \n",
            "  inflating: training_images/eggplant_58.jpg  \n",
            "  inflating: training_images/eggplant_58.xml  \n",
            "  inflating: training_images/eggplant_59.jpg  \n",
            "  inflating: training_images/eggplant_59.xml  \n",
            "  inflating: training_images/eggplant_6.jpg  \n",
            "  inflating: training_images/eggplant_6.xml  \n",
            "  inflating: training_images/eggplant_60.jpg  \n",
            "  inflating: training_images/eggplant_60.xml  \n",
            "  inflating: training_images/eggplant_61.jpg  \n",
            "  inflating: training_images/eggplant_61.xml  \n",
            "  inflating: training_images/eggplant_62.jpg  \n",
            "  inflating: training_images/eggplant_62.xml  \n",
            "  inflating: training_images/eggplant_7.jpg  \n",
            "  inflating: training_images/eggplant_7.xml  \n",
            "  inflating: training_images/eggplant_8.jpg  \n",
            "  inflating: training_images/eggplant_8.xml  \n",
            "  inflating: training_images/eggplant_9.jpg  \n",
            "  inflating: training_images/eggplant_9.xml  \n",
            "  inflating: training_images/image-localization-dataset - Shortcut.lnk  \n",
            "  inflating: training_images/mushroom_1.jpg  \n",
            "  inflating: training_images/mushroom_1.xml  \n",
            "  inflating: training_images/mushroom_10.jpg  \n",
            "  inflating: training_images/mushroom_10.xml  \n",
            "  inflating: training_images/mushroom_11.jpg  \n",
            "  inflating: training_images/mushroom_11.xml  \n",
            "  inflating: training_images/mushroom_12.jpg  \n",
            "  inflating: training_images/mushroom_12.xml  \n",
            "  inflating: training_images/mushroom_13.jpg  \n",
            "  inflating: training_images/mushroom_13.xml  \n",
            "  inflating: training_images/mushroom_14.jpg  \n",
            "  inflating: training_images/mushroom_14.xml  \n",
            "  inflating: training_images/mushroom_15.jpg  \n",
            "  inflating: training_images/mushroom_15.xml  \n",
            "  inflating: training_images/mushroom_16.jpg  \n",
            "  inflating: training_images/mushroom_16.xml  \n",
            "  inflating: training_images/mushroom_17.jpg  \n",
            "  inflating: training_images/mushroom_17.xml  \n",
            "  inflating: training_images/mushroom_18.jpg  \n",
            "  inflating: training_images/mushroom_18.xml  \n",
            "  inflating: training_images/mushroom_19.jpg  \n",
            "  inflating: training_images/mushroom_19.xml  \n",
            "  inflating: training_images/mushroom_2.jpg  \n",
            "  inflating: training_images/mushroom_2.xml  \n",
            "  inflating: training_images/mushroom_20.jpg  \n",
            "  inflating: training_images/mushroom_20.xml  \n",
            "  inflating: training_images/mushroom_21.jpg  \n",
            "  inflating: training_images/mushroom_21.xml  \n",
            "  inflating: training_images/mushroom_22.jpg  \n",
            "  inflating: training_images/mushroom_22.xml  \n",
            "  inflating: training_images/mushroom_23.jpg  \n",
            "  inflating: training_images/mushroom_23.xml  \n",
            "  inflating: training_images/mushroom_24.jpg  \n",
            "  inflating: training_images/mushroom_24.xml  \n",
            "  inflating: training_images/mushroom_25.jpg  \n",
            "  inflating: training_images/mushroom_25.xml  \n",
            "  inflating: training_images/mushroom_26.jpg  \n",
            "  inflating: training_images/mushroom_26.xml  \n",
            "  inflating: training_images/mushroom_27.jpg  \n",
            "  inflating: training_images/mushroom_27.xml  \n",
            "  inflating: training_images/mushroom_28.jpg  \n",
            "  inflating: training_images/mushroom_28.xml  \n",
            "  inflating: training_images/mushroom_29.jpg  \n",
            "  inflating: training_images/mushroom_29.xml  \n",
            "  inflating: training_images/mushroom_3.jpg  \n",
            "  inflating: training_images/mushroom_3.xml  \n",
            "  inflating: training_images/mushroom_30.jpg  \n",
            "  inflating: training_images/mushroom_30.xml  \n",
            "  inflating: training_images/mushroom_31.jpg  \n",
            "  inflating: training_images/mushroom_31.xml  \n",
            "  inflating: training_images/mushroom_32.jpg  \n",
            "  inflating: training_images/mushroom_32.xml  \n",
            "  inflating: training_images/mushroom_33.jpg  \n",
            "  inflating: training_images/mushroom_33.xml  \n",
            "  inflating: training_images/mushroom_34.jpg  \n",
            "  inflating: training_images/mushroom_34.xml  \n",
            "  inflating: training_images/mushroom_35.jpg  \n",
            "  inflating: training_images/mushroom_35.xml  \n",
            "  inflating: training_images/mushroom_36.jpg  \n",
            "  inflating: training_images/mushroom_36.xml  \n",
            "  inflating: training_images/mushroom_37.jpg  \n",
            "  inflating: training_images/mushroom_37.xml  \n",
            "  inflating: training_images/mushroom_38.jpg  \n",
            "  inflating: training_images/mushroom_38.xml  \n",
            "  inflating: training_images/mushroom_39.jpg  \n",
            "  inflating: training_images/mushroom_39.xml  \n",
            "  inflating: training_images/mushroom_4.jpg  \n",
            "  inflating: training_images/mushroom_4.xml  \n",
            "  inflating: training_images/mushroom_40.jpg  \n",
            "  inflating: training_images/mushroom_40.xml  \n",
            "  inflating: training_images/mushroom_41.jpg  \n",
            "  inflating: training_images/mushroom_41.xml  \n",
            "  inflating: training_images/mushroom_42.jpg  \n",
            "  inflating: training_images/mushroom_42.xml  \n",
            "  inflating: training_images/mushroom_43.jpg  \n",
            "  inflating: training_images/mushroom_43.xml  \n",
            "  inflating: training_images/mushroom_44.jpg  \n",
            "  inflating: training_images/mushroom_44.xml  \n",
            "  inflating: training_images/mushroom_45.jpg  \n",
            "  inflating: training_images/mushroom_45.xml  \n",
            "  inflating: training_images/mushroom_46.jpg  \n",
            "  inflating: training_images/mushroom_46.xml  \n",
            "  inflating: training_images/mushroom_47.jpg  \n",
            "  inflating: training_images/mushroom_47.xml  \n",
            "  inflating: training_images/mushroom_48.jpg  \n",
            "  inflating: training_images/mushroom_48.xml  \n",
            "  inflating: training_images/mushroom_49.jpg  \n",
            "  inflating: training_images/mushroom_49.xml  \n",
            "  inflating: training_images/mushroom_5.jpg  \n",
            "  inflating: training_images/mushroom_5.xml  \n",
            "  inflating: training_images/mushroom_50.jpg  \n",
            "  inflating: training_images/mushroom_50.xml  \n",
            "  inflating: training_images/mushroom_51.jpg  \n",
            "  inflating: training_images/mushroom_51.xml  \n",
            "  inflating: training_images/mushroom_52.jpg  \n",
            "  inflating: training_images/mushroom_52.xml  \n",
            "  inflating: training_images/mushroom_53.jpg  \n",
            "  inflating: training_images/mushroom_53.xml  \n",
            "  inflating: training_images/mushroom_54.jpg  \n",
            "  inflating: training_images/mushroom_54.xml  \n",
            "  inflating: training_images/mushroom_55.jpg  \n",
            "  inflating: training_images/mushroom_55.xml  \n",
            "  inflating: training_images/mushroom_56.jpg  \n",
            "  inflating: training_images/mushroom_56.xml  \n",
            "  inflating: training_images/mushroom_57.jpg  \n",
            "  inflating: training_images/mushroom_57.xml  \n",
            "  inflating: training_images/mushroom_58.jpg  \n",
            "  inflating: training_images/mushroom_58.xml  \n",
            "  inflating: training_images/mushroom_59.jpg  \n",
            "  inflating: training_images/mushroom_59.xml  \n",
            "  inflating: training_images/mushroom_6.jpg  \n",
            "  inflating: training_images/mushroom_6.xml  \n",
            "  inflating: training_images/mushroom_60.jpg  \n",
            "  inflating: training_images/mushroom_60.xml  \n",
            "  inflating: training_images/mushroom_61.jpg  \n",
            "  inflating: training_images/mushroom_61.xml  \n",
            "  inflating: training_images/mushroom_7.jpg  \n",
            "  inflating: training_images/mushroom_7.xml  \n",
            "  inflating: training_images/mushroom_8.jpg  \n",
            "  inflating: training_images/mushroom_8.xml  \n",
            "  inflating: training_images/mushroom_9.jpg  \n",
            "  inflating: training_images/mushroom_9.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DERx3xbf8zH",
        "colab_type": "text"
      },
      "source": [
        "## 4) Parsing the images from the dataset\n",
        "\n",
        "We prepare a list of all the files under `training_images` folder which have a `*.jpg` extension ( image files ) using `glob`. We resize them to the `input_dim` and normalize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP8pq3CFFW-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from PIL import Image , ImageDraw\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_dim = 228\n",
        "\n",
        "images = []\n",
        "image_paths = glob.glob( 'training_images/*.jpg' )\n",
        "for imagefile in image_paths:\n",
        "    image = Image.open( imagefile ).resize( ( input_dim , input_dim ))\n",
        "    image = np.asarray( image ) / 255.0\n",
        "    images.append( image )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgu_4WTPggsO",
        "colab_type": "text"
      },
      "source": [
        "## 5) Parsing the bounding box annotations\n",
        "\n",
        "We parse all XML files under the `training_images` folder. These annotations are in the popular `PASCAL-VOC` format. We extract the four bounding box coordinates and normalize them using `input_dim`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sUew-O2FaSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import xmltodict\n",
        "import os\n",
        "\n",
        "bboxes = []\n",
        "annotations_paths = glob.glob( 'training_images/*.xml' )\n",
        "for xmlfile in annotations_paths:\n",
        "    x = xmltodict.parse( open( xmlfile , 'rb' ) )\n",
        "    bndbox = x[ 'annotation' ][ 'object' ][ 'bndbox' ]\n",
        "    bndbox = np.array([ int(bndbox[ 'xmin' ]) , int(bndbox[ 'ymin' ]) , int(bndbox[ 'xmax' ]) , int(bndbox[ 'ymax' ]) ])\n",
        "    bboxes.append( bndbox / input_dim )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHvyZGlYhMYB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 6) Preparing the final datasets\n",
        "\n",
        "Our input will be an array of all the images we parsed earlier. The target output will be the bounding box coordinates.\n",
        "\n",
        "Using scikit-learn's `train_test_split` method, we split our dataset in training and validation datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYl6unq-Fc3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "5e63b6c5-1b59-4d79-e2dc-8739226a8b49"
      },
      "source": [
        "\n",
        "Y = np.array( bboxes )\n",
        "X = np.array( images )\n",
        "\n",
        "Y = np.reshape( Y , ( -1 , 1 , 1 , 4 ) )\n",
        "\n",
        "print( X.shape ) \n",
        "print( Y.shape )\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.1 )\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(186, 228, 228, 3)\n",
            "(186, 1, 1, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7fc979121be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp5mYj7Ylauo",
        "colab_type": "text"
      },
      "source": [
        "## 7) Defining the loss function and evaluation metrics\n",
        "\n",
        "First, we define a method which calculates the intersection over union ( IOU ) of two bounding boxes. In the `custom_loss`, we first calculate Mean Squared Error of the target and predicted bounding boxes. Next, we calculate the IOU loss which is $1 - iou$.\n",
        "\n",
        "Hence, our final loss function is like,\n",
        "\n",
        "$\\Large L( y , y' ) = MSE( y, y') + ( 1 - IOU( y , y' ))$\n",
        "\n",
        "Also, we use IOU as a validation metric to evaluate the model's performance on the testing dataset.\n",
        "\n",
        "**Note: The loss function is a custom implementation. IOU is mostly used as a metric and not in the loss function.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPuyqOpQhPiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_shape = ( input_dim , input_dim , 3 )\n",
        "\n",
        "def calculate_iou( target_boxes , pred_boxes ):\n",
        "    xA = K.maximum( target_boxes[ ... , 0], pred_boxes[ ... , 0] )\n",
        "    yA = K.maximum( target_boxes[ ... , 1], pred_boxes[ ... , 1] )\n",
        "    xB = K.minimum( target_boxes[ ... , 2], pred_boxes[ ... , 2] )\n",
        "    yB = K.minimum( target_boxes[ ... , 3], pred_boxes[ ... , 3] )\n",
        "    interArea = K.maximum( 0.0 , xB - xA ) * K.maximum( 0.0 , yB - yA )\n",
        "    boxAArea = (target_boxes[ ... , 2] - target_boxes[ ... , 0]) * (target_boxes[ ... , 3] - target_boxes[ ... , 1])\n",
        "    boxBArea = (pred_boxes[ ... , 2] - pred_boxes[ ... , 0]) * (pred_boxes[ ... , 3] - pred_boxes[ ... , 1])\n",
        "    iou = interArea / ( boxAArea + boxBArea - interArea )\n",
        "    return iou\n",
        "\n",
        "def custom_loss( y_true , y_pred ):\n",
        "    mse = tf.losses.mean_squared_error( y_true , y_pred ) \n",
        "    iou = calculate_iou( y_true , y_pred ) \n",
        "    return mse + ( 1 - iou )\n",
        "\n",
        "def iou_metric( y_true , y_pred ):\n",
        "    return calculate_iou( y_true , y_pred ) \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hidqxtGNn0-g",
        "colab_type": "text"
      },
      "source": [
        "## 8) Making the CNN model\n",
        "\n",
        "We'll use a CNN model which takes in input an image of shape `( input_dim , input_dim , 3 )` and outputs a vector of shape `( 1 , 1 , 4 )`.\n",
        "\n",
        "*   The `Conv2D` layers will extract features from the image.\n",
        "*   We will not use `Dense` layers as they degrade the performance of our model.\n",
        "\n",
        "We use a small learning rate of 0.0001 so that the learning doesn't stop. Also, we pass the `iou_metric` in the `model.compile()` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wCKt1DZAO0_",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SITou1wjFwPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model_layers = [       \n",
        "    keras.layers.Conv2D( 256 , input_shape=( input_dim , input_dim , 3 ) , kernel_size=( 3 , 3 ) , strides=2 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=2 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    \n",
        "    keras.layers.Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 16 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' ),\n",
        "\n",
        "    keras.layers.Conv2D( 4 , kernel_size=( 2 , 2 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 4 , kernel_size=( 2 , 2 ) , strides=1 , activation='relu' ),\n",
        "    keras.layers.Conv2D( 4 , kernel_size=( 2 , 2 ) , strides=1 , activation='sigmoid' ),\n",
        "]\n",
        "\n",
        "model = keras.Sequential( model_layers )\n",
        "model.compile(\n",
        "\toptimizer=keras.optimizers.Adam( lr=0.0001 ),\n",
        "\tloss=custom_loss,\n",
        "    metrics=[ iou_metric ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PwqHt-YpP8W",
        "colab_type": "text"
      },
      "source": [
        "## 9) Training the model\n",
        "\n",
        "We finally train the model with the validation dataset and save it to the disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqYpnDhlIiJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit( \n",
        "    x_train ,\n",
        "    y_train , \n",
        "    validation_data=( x_test , y_test ),\n",
        "    epochs=50 ,\n",
        "    batch_size=5 \n",
        ")\n",
        "\n",
        "model.save( 'model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-JywIONpb6W",
        "colab_type": "text"
      },
      "source": [
        "## 10) Testing the model on test images\n",
        "\n",
        "The following code will predict bounding boxes for some unseen images, draw them on the image using `ImageDraw` and then save them to a folder ( created with `mkdir` command )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcn3zdf-I5yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!rm -r inference_images\n",
        "!mkdir -v inference_images\n",
        "\n",
        "boxes = model.predict( x_test )\n",
        "for i in range( boxes.shape[0] ):\n",
        "    b = boxes[ i , 0 , 0 , 0 : 4 ] * input_dim\n",
        "    img = x_test[i] * 255\n",
        "    source_img = Image.fromarray( img.astype( np.uint8 ) , 'RGB' )\n",
        "    draw = ImageDraw.Draw( source_img )\n",
        "    draw.rectangle( b , outline=\"black\" )\n",
        "    source_img.save( 'inference_images/image_{}.png'.format( i + 1 ) , 'png' )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMysv18NqMMI",
        "colab_type": "text"
      },
      "source": [
        "## 11) Print the average IOU\n",
        "\n",
        "We will calculate the average IOU score over the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgrJJxEOpOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def calculate_avg_iou( target_boxes , pred_boxes ):\n",
        "    xA = np.maximum( target_boxes[ ... , 0], pred_boxes[ ... , 0] )\n",
        "    yA = np.maximum( target_boxes[ ... , 1], pred_boxes[ ... , 1] )\n",
        "    xB = np.minimum( target_boxes[ ... , 2], pred_boxes[ ... , 2] )\n",
        "    yB = np.minimum( target_boxes[ ... , 3], pred_boxes[ ... , 3] )\n",
        "    interArea = np.maximum(0.0, xB - xA ) * np.maximum(0.0, yB - yA )\n",
        "    boxAArea = (target_boxes[ ... , 2] - target_boxes[ ... , 0]) * (target_boxes[ ... , 3] - target_boxes[ ... , 1])\n",
        "    boxBArea = (pred_boxes[ ... , 2] - pred_boxes[ ... , 0]) * (pred_boxes[ ... , 3] - pred_boxes[ ... , 1])\n",
        "    iou = interArea / ( boxAArea + boxBArea - interArea )\n",
        "    return iou\n",
        "\n",
        "target_boxes = y_test * input_dim\n",
        "pred = model.predict( x_test )\n",
        "pred_boxes = pred[ ... , 0 : 4 ] * input_dim\n",
        "\n",
        "iou_scores = calculate_avg_iou( target_boxes , pred_boxes )\n",
        "print( 'Mean IOU score {}'.format( iou_scores.mean() ) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdJoOVBoY5AI",
        "colab_type": "text"
      },
      "source": [
        "## ( Optional ) Convert the Keras model to TensorFlow Lite model\n",
        "\n",
        "We can convert the Keras models ( .h5 ) to a TensorFlow Lite model ( .tflite ) for using it with Android or iOS devices.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfKGZOTcYZbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file( 'model.h5' , custom_objects={ 'custom_loss' : custom_loss , 'iou_metric' : iou_metric } ) \n",
        "converter.post_training_quantize = True\n",
        "buffer = converter.convert()\n",
        "open( 'model.tflite' , 'wb' ).write( buffer )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}